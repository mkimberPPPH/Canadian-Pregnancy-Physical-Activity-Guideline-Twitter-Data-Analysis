{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Twitter Scraping for Researchers\n",
    "\n",
    "This notebook was written by [John Simpson](mailto:john.simpson@computecanada.ca) and is meant to provide some simple, working examples for researchers who would like to collect information from Twitter.  While Twitter provides their own tools and libraries for this they are a little too granular and possibly unfamiliar to many in the research community.  For this reason this workbook uses a Python library build by a third party that greatly streamlines the process of collecting tweets.\n",
    "\n",
    "This notebook assumes:\n",
    "\n",
    "1. Basic familiarity with the Jupyter Notebook environment.\n",
    "2. A functioning python environment on the system it is run in and that you have the authority to install software on it.\n",
    "3. That you have a developer account with Twitter [HERE](https://developer.twitter.com/en/)\n",
    "4. That you have an app created with Twitter [HERE](https://developer.twitter.com/en/apps)\n",
    "5. That you pay attention to the various notes and warnings around the cells.\n",
    "\n",
    "I won't promise you any support but if you send me a note I'll help as I am able.\n",
    "\n",
    "The Python library used is called TwitterAPI (no space) and it can be found at https://github.com/geduldig/TwitterAPI.  Most of the code that is throughout this workbook is drawn directly from the examples on these pages.\n",
    "\n",
    "What this workbook does not do that most researchers will likely need to add to their project is show how to put the tweets that are scraped into a database.  If resesearchers are interested in writing to a database then they should find and consult the documentation available for connecting that database to Python and then substitute the appropriate commands for the sections of this workbook that write to files.\n",
    "\n",
    "With all this said, let's get started by installing the TwitterAPI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the TwitterAPI library installed on the system we should be able to open it for use throughout this workbook with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note that almost every piece of code in the remainder of this workbook assumes that the cell above has been run in advance of it being run.  If you open the workbook and immediately try to run a cell other than this one first then it is likely that you will receive an error.  Simply run the cell above and try to run the cell you want to run again.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "Use of this workbook–and the Twitter Developer API in general—requires a developer account from Twitter.  Unlike the early days of Twitter when anyone with a regular Twitter account who requested a developer account would just be given one Twitter now screens requests for developer accounts, a process that can stall getting started by many days.  If you had a developer account previously and created applications (apps) that used the Twitter application programming interfaces (APIs) then you may still be able to use these apps to do some work but it is possible that their ability to access the Twitter archive has been reduced and, if so, that you'll need to apply for a new developer account to correct this.  A developer account may be requested from https://developer.twitter.com/en/apply/user.\n",
    "\n",
    "As the [TwitterAPI Documentation](https://geduldig.github.io/TwitterAPI/authentication.html) points out: _Twitter supports both user and application authentication, called oAuth 1 and oAuth 2, respectively. User authentication gives you access to all API endpoints, basically read and write persmission. It is also required in order to using the Streaming API. Application authentication gives you access to just the read portion of the API – so, no creating or destroying tweets. Application authentication, however, has elevated rate limits._  \n",
    "We will use oAuth1 throughout this workbook even though we'll only be reading tweets since it can be used in more situations (in particular when we try to read from the streaming API).  If it is necessary to read Twitter API endpoints (other than the streaming endpoint) at a faster rate than this workbook initially provides then consider switching to oAuth2.\n",
    "\n",
    "You will need oAuth1 to do any of the following:\n",
    "\n",
    "* Post Tweets or other resources;\n",
    "* Connect to Streaming endpoints;\n",
    "* Search for users;\n",
    "* Use any geo endpoint;\n",
    "* Access Direct Messages or account credentials;\n",
    "* Retrieve user's email addresses;\n",
    "\n",
    "Both authentication methods will require you to collect some information about keys and tokens and paste it into the appropriate section of the cell below.  This key and token information is generated when you create a profile for an app on the Twitter Developer site.  App profiles can be created at https://developer.twitter.com/en/apps.  That same page will hold a list of all the profiles that you have created and clicking on the \"Details\" button for each app will bring you to a summary page.  There will be a link/tab near the top of the page called \"Keys and Tokens\" and clicking this will bring you to the page with the key and token information.\n",
    "\n",
    "Paste in the required key and token information from the Twitter Developer site into the cell below and then run it in order to use this workbook.  Remember that you'll need to run the cell below (which loads your credentials) and _one_ of the authorization methods below (default to oAuth1 unless you are sure you need oAuth2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''\n",
    "API_KEY_SECRET = ''\n",
    "ACCESS_TOKEN = ''\n",
    "ACCESS_TOKEN_SECRET = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! IMPORTANT !!!\n",
    "\n",
    "If the code in the cells below fails it is likely because you need to put your own authentication details in the cell above.  More specifically, you will need to copy-paste in the api key, api key secret, access token, and access token secret from the \"keys and tokens\" tab of the description of the app that you set up with your Twitter developer account.\n",
    "\n",
    "!!! IMPORTANT !!!\n",
    "\n",
    "### oAuth1 (User Identification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TwitterAPI(API_KEY, \n",
    "                 API_KEY_SECRET, \n",
    "                 ACCESS_TOKEN, \n",
    "                 ACCESS_TOKEN_SECRET)\n",
    "\n",
    "api.auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If successful the output of the cell above should look something like:\n",
    "\n",
    "    <requests_oauthlib.oauth1_auth.OAuth1 at 0x107b8bba8>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premium Access\n",
    "\n",
    "1. Setting up a dev environment.  Within the Twitter developer site click on your name in the top right corner.  From the menu select \"Dev environments\".  Follow the interface to create the environments that you would like and associate an app with each.\n",
    "2. Note the name of each dev environment because it will go into one of the variables called `LABEL`, below.  I named my 30-Day development environment \"30DayTesting\" and my full archive development environment \"fullArchiveTesting\".  So in the 30 Day example I set `LABEL` to \"30DayTesting\" and in the Full Archive example I set `LABEL` to \"fullArchiveTesting\".\n",
    "\n",
    "To see exactly what is available in the premium sandbox have a look at the overview [HERE](https://developer.twitter.com/en/docs/tweets/search/overview/premium.html) and the search guide [HERE](https://developer.twitter.com/en/docs/tweets/search/guides/premium-operators).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Day\n",
    "\n",
    "This will access Tweets with your selected search term(s) in the past 30 days. You will need to set the name of the LABEL when you create your 30-Day development environment. Please note there is a rate limit for the sanbox Twitter developer account. 30-day will complete a maximum of 250 searches/month and 25,000 Tweets returned. If this limit is reached you will receieve a error code of 429."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "SEARCH_TERM =\n",
    "PRODUCT = '30day'\n",
    "LABEL = \n",
    "\n",
    "r = api.request('tweets/search/%s/:%s' % (PRODUCT, LABEL), \n",
    "                {'query':SEARCH_TERM})\n",
    "\n",
    "for item in r:\n",
    "    print(item['text'] if 'text' in item else item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Archive\n",
    "\n",
    "This will access Tweets with your selected search term(s) from your chosen date range. Please note there is a rate limit for the sanbox Twitter developer account. Full archive will complete a maximum of 50 searches a month and 5000 Tweets returned. If this limit is reached you will receieve a error code of 429.\n",
    "\n",
    "Both cells below will need to be run in order to retrieve the Full text of the retrieved Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Archive Tweets. The next cell will need to be run to get the FULL TEXT Tweets.\n",
    "from TwitterAPI import TwitterAPI, TwitterPager\n",
    "\n",
    "SEARCH_TERM = 'pregnancy' 'fitness'\n",
    "PRODUCT = 'fullarchive'\n",
    "LABEL = 'Fullarchive'\n",
    "\n",
    "pager = TwitterPager(api, 'tweets/search/%s/:%s' % (PRODUCT, LABEL), {'query': SEARCH_TERM, 'fromDate': 20200101000,'toDate':20200601000})\n",
    "\n",
    "pagerObject =[]\n",
    "\n",
    "for item in pager.get_iterator(wait=30):\n",
    "    pagerObject.append(item)\n",
    "    line = item['text'] + '|' + str(item['id']) + '|' + str(item['created_at']) + '|' + str(item['user']['location']) + '|' + str(item['user']['name']) + '|' + str(item['user']['screen_name'])\n",
    "    print(line if 'text' in item else item)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/tweets/search/overview/premium.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Full Archive Tweets with full text\n",
    "\n",
    "for item in pagerObject:\n",
    "    if 'extended_tweet' in item.keys():\n",
    "        tweet_text = item['extended_tweet']['full_text']\n",
    "    else:\n",
    "        tweet_text = item['text']\n",
    "    line = tweet_text + '|' + str(item['id']) + '|' + str(item['created_at']) + '|' + str(item['user']['location']) + '|' + str(item['user']['name']) + '|' + str(item['user']['screen_name'])\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB, Pymongo and Robo3T\n",
    "\n",
    "After all Tweets have been collected from the 30-day or Full archive environment, they must be moved into a database. MongoDB is a database program used in this project. \n",
    "\n",
    "MongoDB installation is required prior to importing pymongo.\n",
    "\n",
    "The value given to db will be the name of the Tweet collection on MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.notebooktest2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.notebooktest2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Tweets into Robo3T\n",
    "\n",
    "Tweets were then moved in Robo 3T, a graphical user interface which allows interaction with the Tweets pulled from your dev environment. \n",
    "\n",
    "Robo 3T installation is required prior to importing Tweets from MongoDB.\n",
    "\n",
    "The value given posts will be the name of the collection Tweets will be stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving tweets into Robo 3T database\n",
    "posts = db.notebooktestMK\n",
    "for item in pagerObject:\n",
    "        if 'extended_tweet' in item.keys():\n",
    "            tweet_text = item['extended_tweet']['full_text']\n",
    "        else:\n",
    "            tweet_text = item['text']\n",
    "        \n",
    "        post = {\"text\": tweet_text,\n",
    "            \"id\": str(item['id']),\n",
    "            \"created_at\": str(item['created_at']),\n",
    "            \"user_location\": str(item['user']['location']), \n",
    "            \"user_name\":str(item['user']['name']),\n",
    "            \"user_screen_name\": str(item['user']['screen_name']),\n",
    "            \"search_term\": \"pregnancy_fitness\"}\n",
    "        post_id = posts.insert_one(post).inserted_id\n",
    "        print(post_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Tweets into one collection, removing duplicates and converting dates to pymongo format\n",
    "\n",
    "The following cells will move all Tweets into one collection with duplicates removed and dates listed in pymongo format. These steps were required for the selected analysis of this project.\n",
    "\n",
    "\n",
    "To complete analysis on all of your collected Tweets, they will need to be moved into one large collection. As Tweets can be retweeted unlimited times, there may be duplicates in your Tweets collection. It may be important to remove retweeted Tweets from your collection for analysis.\n",
    "\n",
    "In order to complete analysis on the date period in which Tweets are posted, converting the dates from the collected Tweets in pymongo format was required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collection names database\n",
    "\n",
    "This cell will list all of the collection in your Robo 3T database. It is required to run in order to move all Tweets into one large collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install datetime\n",
    "\n",
    "This cell will install necessary material to convert Tweets dates into pymongo format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move all Tweets in one collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting tweet ID's into doc\n",
    "tweetIDs = set()\n",
    "for doc in posts.find():\n",
    "    #print(doc)\n",
    "    tweetIDs.add(doc['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting tweets into one collection with dates in pymongo format and duplicates removed\n",
    "tweetIDs = set()\n",
    "posts = db.alltweets\n",
    "for col in db.collection_names():\n",
    "    for post in db[col].find():\n",
    "        if post['id'] not in tweetIDs:\n",
    "            tweetIDs.add(post['id'])\n",
    "            created_at_num = doc['created_at']\n",
    "            postb = {\"text\": post['text'],\n",
    "            \"id\": post['id'],\n",
    "            \"created_at\": post['created_at'],\n",
    "            \"created_at_num\":datetime.strptime(created_at_num, '%a %b %d %H:%M:%S +0000 %Y'),\n",
    "            \"user_location\": post['user_location'], \n",
    "            \"user_name\":post['user_name'],\n",
    "            \"user_screen_name\": post['user_screen_name'],\n",
    "            \"search_term\": post['search_term']}\n",
    "            post_id = posts.insert_one(postb).inserted_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all Tweets were moved into excel for analysis. This was done using a JSON to CSV script converter. \n",
    "\n",
    "Please note this was the method used for this project, however there are a number of other options available for managing and analyzing your mined Tweets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
